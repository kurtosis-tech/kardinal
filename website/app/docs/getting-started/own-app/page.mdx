import Collapsible from '@/components/Collapsible';

# Use Kardinal with your own application

Getting started takes just a few minutes, assuming you have [installed Kardinal](./getting-started/install) already. This guide will walk you through the steps to get started:

1. Annotate your application entrypoint
2. Deploy your application via Kardinal
3. Create a dev flow

### Prerequisites

To use Kardinal with your application, you will need a development Kubernetes cluster with Istio installed.

It's not important that your production cluster uses Istio. Kardinal will manage everything related to Istio on your development cluster, and your application should work just fine.

Then, you'll need to install the Kardinal CLI and deploy the Kardinal Manager on your application, as described in the [install Kardinal guide](./getting-started/install) 

Then, make sure your application is using distributed tracing. Kardinal uses your trace IDs to route requests between different development versions of services to implement logical environment isolation.

Kardinal integrates with the following trace headers (tracing systems) out of the box:

<Collapsible title="Supported Distributed Tracing Systems">
```
"x-b3-traceid",           -- Zipkin B3
"x-request-id",           -- General request ID, often used for tracing
"x-cloud-trace-context",  -- Google Cloud Trace
"x-amzn-trace-id",        -- AWS X-Ray
"traceparent",            -- W3C Trace Context
"uber-trace-id",          -- Jaeger
"x-datadog-trace-id"      -- Datadog
```

If you want to use a tracing system that isn't listed here, you can submit an [issue](https://github.com/kurtosis-tech/kardinal/issues) or a [PR](https://github.com/kurtosis-tech/kardinal/pulls) and we'll add it.
</Collapsible>

### Step 1: Annotate the application entrypoint

Kardinal expects there to be exactly one service in your Kubernetes manifest that acts as an entrypoint into the cluster, usually an load balancer or gateway of some sort that routes traffic into the cluster.

To get started, you just need to add the *`kardinal.dev.service/ingress`* and *`kardinal.dev.service/host`* annotations to your manifest to mark this entrypoint:

- *`kardinal.dev.service/ingress`*
  - Should be set to `true` for whichever service is an entrypoint into the cluster.
- *`kardinal.dev.service/host`*
  - Used to give the entrypoint a hostname you can use to access it outside of the cluster.
  - Should integrate with whatever system you already use to set up DNS routing into your clusters.
  - If you're using minikube, this can be something like `main.app.localhost`.

Here is an example for how this annotation might look for a frontend load balancer, configured to be accessible in Kardinal via `main.app.localhost`:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: frontend-external
  annotations:
    kardinal.dev.service/ingress: "true"
    kardinal.dev.service/host: "main.app.localhost"
spec:
  type: LoadBalancer
  selector:
    app: frontend
  ports:
    - name: http
      port: 80
      targetPort: 8080
      protocl: TCP
      appProtocol: HTTP
```


### Step 2: Deploy the main version of your application

Okay, now that we've got Kardinal integrated, let's deploy our application. Run:
    
```bash
kardinal deploy -k <path-to-k8s-manifest-annotated-with-Kardinal>
```
    
You should now be able to view your application in the Kardinal dashboard with:
    
```bash
kardinal dashboard
```


### Step 3: Create a dev flow
    
First, create a flow. Pick a service in your application to test a dev image on and run:
    
```bash
kardinal flow create <service-name> <your/new-dev-image:dev>
```

You should see some output like:
```bash
kardinal flow create frontend kurtosistech/frontend:demo-frontend
INFO[0000] Using tenant UUID 483e3371-ec18-40ca-aaee-54df597d1fd2 
INFO[0000] Creating service frontend with image kurtosistech/frontend:demo-frontend in development mode... 
Flow "dev-qlm1214pgt" created. Access it on:
üåê http://dev-qlm1214pgt.app.localhost
```

You can view all the flows in your cluster in the Kardinal dashboard:

```bash
kardinal dashboard
```    

If you run `kardinal gateway <flow-id>`, Kardinal will open a gateway to the entrypoint of the flow - whatever service of your application was annotated with the `kardinal.dev.service/ingress` annotation. Whether the service is a frontend or a backend service, you will be able to access the dev flow by making requests to the returned endpoint.
    
```bash
$ kardinal gateway dev-qlm1214pgt
INFO[0000] Using tenant UUID 483e3371-ec18-40ca-aaee-54df597d1fd2 
2024/08/07 13:50:52 Starting gateway for host: dev-qlm1214pgt.app.localhost
2024/08/07 13:50:52 All pods in namespace prod are ready and flowId dev-qlm1214pgt found
2024/08/07 13:50:52 Proxy server for host dev-qlm1214pgt.app.localhost started on http://localhost:9060
```
